{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51bf4dbc",
   "metadata": {},
   "source": [
    "# 优化模型\n",
    "\n",
    "## 集成算法\n",
    "\n",
    "集成算法是提高准确度的有效方法之一，主要有以下几种：\n",
    "- 袋装Bagging算法\n",
    "    - 先将训练集分离成多个子集，然后通过各个子集训练多个模型\n",
    "- 提升Boosting算法\n",
    "    - 训练多个模型并组成一个序列，序列中的每一个模型都会修正前一个模型的错误\n",
    "- 投票Voting算法\n",
    "    - 训练多个模型，并采用样本统计来提高模型的准确度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c562c98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T02:18:01.801327Z",
     "start_time": "2021-12-02T02:17:57.192210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.770745044429255"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 袋装算法：提高分类准确率，通过给定组合的方式获得最优解\n",
    "# 三种模型：袋装决策树（Bagged Decision Trees）；随机森林（Random Forest）；极端随机树（Extra Trees）\n",
    "\n",
    "# 袋装随机树：在方差很大时非常有效\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'RuntimeWarning')\n",
    "\n",
    "filename = 'pima_data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_csv(filename, names=names)\n",
    "# 将数据分为输入数据和输出结果\n",
    "array = data.values\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "cart = DecisionTreeClassifier()\n",
    "num_tree = 100\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_tree, random_state=seed)\n",
    "result = cross_val_score(model, X, Y, cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47729a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T02:20:08.695797Z",
     "start_time": "2021-12-02T02:20:05.774612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7733766233766234"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机森林\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "max_features = 3\n",
    "model = RandomForestClassifier(n_estimators=num_tree, random_state=seed, max_features=max_features)\n",
    "result = cross_val_score(model, X, Y, cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ea7b92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T02:23:20.854806Z",
     "start_time": "2021-12-02T02:23:17.856354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.762987012987013"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 极端随机树\n",
    "# 与随机森林的两个主要区别\n",
    "# 1、随机森林用的是Bagging模型；极端随机树是每棵决策树应用的是相同的全部训练样本\n",
    "# 2、随机森林是在一个随机子集内得到最优分叉特征属性；极端树是完全随机地选择分叉属性特征\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "max_features = 7\n",
    "model = ExtraTreesClassifier(n_estimators=num_tree, random_state=seed, max_features=max_features)\n",
    "result = cross_val_score(model, X, Y, cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "883f97b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T02:25:55.590918Z",
     "start_time": "2021-12-02T02:25:54.342551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.760457963089542"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提升算法：提高弱分类算法准确度的方法\n",
    "# 常见两种：1、AdaBoost；2、随机梯度提升 Stochastic Gradient Boosting\n",
    "\n",
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "num_tree = 30\n",
    "model = AdaBoostClassifier(n_estimators=num_tree, random_state=seed)\n",
    "result = cross_val_score(model, X, Y, cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "145d6028",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T02:27:42.784863Z",
     "start_time": "2021-12-02T02:27:40.995649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681989063568012"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机梯度提升 GBM：要找到某个函数最大值，最好的办法是沿着该函数的梯度方向探寻\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "num_tree = 100\n",
    "model = GradientBoostingClassifier(n_estimators=num_tree, random_state=seed)\n",
    "result = cross_val_score(model, X, Y, cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4f11d47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T02:35:43.245410Z",
     "start_time": "2021-12-02T02:35:42.549296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7329801777170197"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 投票算法 Voting：多个机器学习算法的集成算法，通过增加预测结果权重 ，提高算法准确度\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "models = []\n",
    "model_logistic = LogisticRegression()\n",
    "models.append(('logistic', model_logistic))\n",
    "model_cart = DecisionTreeClassifier()\n",
    "models.append(('cart', model_cart))\n",
    "model_svc = SVC()\n",
    "models.append(('svm', model_svc))\n",
    "ensemble_model = VotingClassifier(estimators=models)\n",
    "result = cross_val_score(ensemble_model, X, Y, cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17102ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
